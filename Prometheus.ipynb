{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (0.1.29)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.57 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-llms-openai) (0.10.67)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-llms-openai) (1.41.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2023.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-huggingface-api in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.41 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.10.67)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.0.8)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.41.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (10.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.9.4)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2023.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (2.14.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface-api) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\ai-ml\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-llms-huggingface-api\n",
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\AI-ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277b45117e264f63ba1cc0fd0821f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\AI-ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fde9366029c4b4fb290c86d553ced47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:  39%|###9      | 776M/1.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\AI-ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--prometheus-eval--prometheus-7b-v2.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5d38263e2c439b88c2ff66f595e7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee9d0e47a5c4862a6aca83b06535975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a2895b9b67472fab172c20182d6e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037fd574238448a9b01f964d2105044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2653b38a412c45119e67327fc2a14ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/789M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = 'prometheus-eval/prometheus-7b-v2.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# HF_TOKEN = \"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\"\n",
    "\n",
    "# prometheus_llm = HuggingFaceInferenceAPI(\n",
    "#     model_name='prometheus-eval/prometheus-7b-v2.0',\n",
    "#     token=HF_TOKEN,\n",
    "#     temperature=0.1,\n",
    "#     do_sample=True,\n",
    "#     top_p=0.95,\n",
    "#     top_k=40,\n",
    "#     repetition_penalty=1.1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('hello.env')\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = GoogleGenerativeAI(google_api_key=api_key, model='models/text-bison-001', temperature=0.9)\n",
    "instructor_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", task_type=\"retrieval_query\")\n",
    "\n",
    "vectordb_file_path = \"faiss_index\"\n",
    "\n",
    "def create_vector_db():\n",
    "    \"\"\"\n",
    "    Create a FAISS vector database from the CSV file and save it locally.\n",
    "    \"\"\"\n",
    "    loader = CSVLoader(file_path=\"project.csv\", source_column=\"States + UTs\")\n",
    "    data = loader.load()\n",
    "\n",
    "    vectordb = FAISS.from_documents(documents=data, embedding=instructor_embeddings)\n",
    "    vectordb.save_local(vectordb_file_path)\n",
    "    print(\"Vector database created and saved successfully.\")\n",
    "\n",
    "def get_qa_chain():\n",
    "    \"\"\"\n",
    "    Load the FAISS vector database and create a RetrievalQA chain for question answering.\n",
    "    \"\"\"\n",
    "    vectordb = FAISS.load_local(vectordb_file_path, instructor_embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectordb.as_retriever(score_threshold=0.7)\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    Given the following context and a question, generate an answer based on this context only.\n",
    "    In the answer try to provide as much text as possible from the \"response\" section in the source document context without making much changes.\n",
    "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {question}\n",
    "    Please provide a detailed and comprehensive answer that includes multiple aspects and detailed explanations where possible.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    chain_type_kwargs = {\"prompt\": prompt}\n",
    "    \n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs\n",
    "    )\n",
    "\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prometheus_correctness_eval_prompt_template = \"\"\"###Task Description: An instruction (might include an Input inside it), a query, a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given. \n",
    "\t\t\t1. Write a detailed feedback that assesses the quality of the response strictly based on the given score rubric, not evaluating in general. \n",
    "\t\t\t2. After writing a feedback, write a score that is either 1 or 2 or 3 or 4 or 5. You should refer to the score rubric. \n",
    "\t\t\t3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (1 or 2 or 3 or 4 or 5)\" \n",
    "\t\t\t4. Please do not generate any other opening, closing, and explanations. \n",
    "            5. Only evaluate on common things between generated answer and reference answer. Don't evaluate on things which are present in reference answer but not in generated answer.\n",
    "\n",
    "\t\t\t###The instruction to evaluate: Your task is to evaluate the generated answer and reference answer for the query: {query}\n",
    "\t\t\t\n",
    "            ###Generate answer to evaluate: {generated_answer} \n",
    "\n",
    "            ###Reference Answer (Score 5): {reference_answer}\n",
    "            \n",
    "    \t\t###Score Rubrics: \n",
    "            Score 1: If the generated answer is not relevant to the user query and reference answer.\n",
    "            Score 2: If the generated answer is according to reference answer but not relevant to user query.\n",
    "            Score 3: If the generated answer is relevant to the user query and reference answer but contains mistakes.\n",
    "    \t\tScore 4: If the generated answer is relevant to the user query and has the exact same metrics as the reference answer, but it is not as concise.\n",
    "            Score 5: If the generated answer is relevant to the user query and fully correct according to the reference answer.\n",
    "    \n",
    "    \t\t###Feedback:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_answer(query, generated_answer, reference_answer):\n",
    "#     prompt = prometheus_correctness_eval_prompt_template.format(\n",
    "#         query=query,\n",
    "#         generated_answer=generated_answer,\n",
    "#         reference_answer=reference_answer\n",
    "#     )\n",
    "    \n",
    "#     # Get the evaluation from Prometheus\n",
    "#     response = prometheus_llm(prompt)\n",
    "#     evaluation_result = response['text']\n",
    "    \n",
    "#     return evaluation_result\n",
    "\n",
    "def evaluate_answer(query, generated_answer, reference_answer):\n",
    "    prompt = prometheus_correctness_eval_prompt_template.format(\n",
    "        query=query,\n",
    "        generated_answer=generated_answer,\n",
    "        reference_answer=reference_answer\n",
    "    )\n",
    "    \n",
    "    # Encode the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate evaluation\n",
    "    outputs = model.generate(**inputs, max_length=512, temperature=0.1, top_p=0.95, top_k=40, repetition_penalty=1.1)\n",
    "    evaluation_result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created and saved successfully.\n",
      "Answer: The spiritual practices of Assam include:\n",
      "    * Sankirtan meditation: a Vaishnavite practice involving group singing, dancing, and music as meditative practices.\n",
      "    * Herbal steam baths: use of local herbs in healing rituals.\n",
      "    * Traditional Assamese massage: traditional massage techniques.\n",
      "    * Use of local medicinal plants for healing.\n",
      "\n",
      "For more information, please refer to the following link:\n",
      "[https://www.incredibleindia.org/spiritual-and-wellness-tourism/meditation-and-healing-tours/assam/]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'HuggingFaceInferenceAPI' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate the generated answer\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# For demonstration, you may need to use actual reference answers\u001b[39;00m\n\u001b[0;32m     18\u001b[0m reference_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSankirtan. Vaishnavism. Group singing, dancing, and music as meditative practices. Devotion through music.Herbal steam baths. Traditional Assamese massage. Use of local medicinal plants for healing. 1. Kamakhya Temple, Guwahati; 2. Umananda Temple, Guwahati; 3. Sivasagar Sivadol, Sivasagar; 4. Mahamaya Temple, Bongaigaon; 5. Hajo Powa Mecca, Hajo\tImportant religious and historical sites\tAvailable through hotels and tourism boards\tOctober to April\t5-7 days Airport: Lokpriya Gopinath Bordoloi International Airport, Guwahati (GAU) Railway Station: Guwahati Railway Station Road\tHeritage hotels in Guwahati, guest houses\tTemple volunteering, cultural preservation projects\t1. Lyangcha, 2. Maach Jhol, 3. Alu Pitika, 4. Masor tenga, 5. Bilahi Maas, 6. Bora Sawul, 7. Haq Maas, 8. Koldil Chicken, 9. Masor Koni, 10. Payokh, 11. Til Pitha\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your reference answer\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m evaluation_result \u001b[38;5;241m=\u001b[39m evaluate_answer(question, answer, reference_answer)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, evaluation_result)\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36mevaluate_answer\u001b[1;34m(query, generated_answer, reference_answer)\u001b[0m\n\u001b[0;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prometheus_correctness_eval_prompt_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m      3\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m      4\u001b[0m     generated_answer\u001b[38;5;241m=\u001b[39mgenerated_answer,\n\u001b[0;32m      5\u001b[0m     reference_answer\u001b[38;5;241m=\u001b[39mreference_answer\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get the evaluation from Prometheus\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m prometheus_llm(prompt)\n\u001b[0;32m     10\u001b[0m evaluation_result \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evaluation_result\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HuggingFaceInferenceAPI' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    create_vector_db()\n",
    "    chain = get_qa_chain()\n",
    "    \n",
    "    # Take user input and get the answer from the QA chain\n",
    "    while True:\n",
    "        question = input(\"Enter your question (or 'exit' to quit): \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        result = chain({\"query\": question})\n",
    "        answer = result['result']\n",
    "        print(\"Answer:\", answer)\n",
    "        \n",
    "        # Evaluate the generated answer\n",
    "        # For demonstration, you may need to use actual reference answers\n",
    "        reference_answer = \"Sankirtan. Vaishnavism. Group singing, dancing, and music as meditative practices. Devotion through music.Herbal steam baths. Traditional Assamese massage. Use of local medicinal plants for healing. 1. Kamakhya Temple, Guwahati; 2. Umananda Temple, Guwahati; 3. Sivasagar Sivadol, Sivasagar; 4. Mahamaya Temple, Bongaigaon; 5. Hajo Powa Mecca, Hajo\tImportant religious and historical sites\tAvailable through hotels and tourism boards\tOctober to April\t5-7 days Airport: Lokpriya Gopinath Bordoloi International Airport, Guwahati (GAU) Railway Station: Guwahati Railway Station Road\tHeritage hotels in Guwahati, guest houses\tTemple volunteering, cultural preservation projects\t1. Lyangcha, 2. Maach Jhol, 3. Alu Pitika, 4. Masor tenga, 5. Bilahi Maas, 6. Bora Sawul, 7. Haq Maas, 8. Koldil Chicken, 9. Masor Koni, 10. Payokh, 11. Til Pitha\"  # Replace with your reference answer\n",
    "        evaluation_result = evaluate_answer(question, answer, reference_answer)\n",
    "        print(\"Evaluation Result:\", evaluation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
