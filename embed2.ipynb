{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "from hello import api_key\n",
    "import os\n",
    "os.environ['GOOGLE_AI_KEY']=api_key\n",
    "llm=GooglePalm(google_api_key=api_key,temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path=\"project.csv\", source_column=\"States + UTs\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleGenerativeAIEmbeddings\n__root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m e \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mlen\u001b[39m(e)\n\u001b[1;32m---> 15\u001b[0m instructor_embeddings \u001b[38;5;241m=\u001b[39m GoogleGenerativeAIEmbeddings(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/embedding-001\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mdata,embedding\u001b[38;5;241m=\u001b[39minstructor_embeddings)\n\u001b[0;32m     21\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriever(score_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\AI-ML\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for GoogleGenerativeAIEmbeddings\n__root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(google_api_key=api_key,model=\"models/embedding-001\")\n",
    "e = embeddings.embed_query(\"states\")\n",
    "len(e)\n",
    "\n",
    "instructor_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\", task_type=\"retrieval_query\"\n",
    ")\n",
    "vectordb = FAISS.from_documents(documents=data,embedding=instructor_embeddings)\n",
    "\n",
    "\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)\n",
    "rdocs = retriever.get_relevant_documents(\"Goa\")\n",
    "rdocs\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=retriever, input_key=\"query\",return_source_documents=True, chain_type_kwargs=chain_type_kwargs)\n",
    "chain(\"spirtuality of Goa and its origin\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
